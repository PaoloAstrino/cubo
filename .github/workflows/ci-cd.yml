name: CI/CD Pipeline

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch: # Allow manual trigger

jobs:
  test:
    runs-on: windows-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~\AppData\Local\pip\Cache
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt
          python -m pip install -r requirements-dev.txt

      - name: Test Dolphin integration (optional)
        run: |
          $env:PYTHONPATH = "$env:GITHUB_WORKSPACE"
          # Test Dolphin download script (without actually downloading)
          python -c "import sys; sys.path.insert(0, '.'); from download_dolphin import download_dolphin_model, test_dolphin_model; print('Dolphin scripts import successfully')"
          # Test enhanced document processor initialization
          python -c "from src.enhanced_document_processor import EnhancedDocumentProcessor; from src.config import config; print('Enhanced processor imports successfully')"
          # Test Dolphin processor import
          python -c "from src.dolphin_processor import DolphinProcessor; print('Dolphin processor imports successfully')"
        continue-on-error: true # Don't fail if Dolphin model not available in CI

      - name: Run tests
        run: |
          $env:PYTHONPATH = "$env:GITHUB_WORKSPACE"
          python -m pytest tests/ -v --tb=short --cov=src --cov-report=xml --cov-report=term --cov-fail-under=85
          # Ensure new backend service tests are included
          python -m pytest tests/test_thread_manager.py tests/test_error_recovery.py tests/test_health_monitor.py tests/test_service_manager.py -v

      - name: Run backend service tests
        run: |
          $env:PYTHONPATH = "$env:GITHUB_WORKSPACE"
          # Test service manager integration
          python -c "from src.service_manager import get_service_manager; sm = get_service_manager(); status = sm.get_system_status(); print(f'Service manager status: {status}'); sm.shutdown()"
          # Test thread manager
          python -c "from src.thread_manager import ThreadManager; tm = ThreadManager(max_workers=2); future = tm.submit_task(lambda: 42); result = future.result(); assert result == 42; tm.shutdown()"
          # Test error recovery
          python -c "from src.error_recovery import ErrorRecoveryManager; erm = ErrorRecoveryManager(); result = erm.execute_with_recovery('test', lambda: 'success'); assert result == 'success'"
          # Test health monitor
          python -c "from src.health_monitor import HealthMonitor; hm = HealthMonitor(); status = hm.get_health_status(); assert 'overall_status' in status"

      - name: Test enhanced document processing
        run: |
          $env:PYTHONPATH = "$env:GITHUB_WORKSPACE"
          # Test automatic enhanced processing detection
          python -c "
          from src.document_loader import DocumentLoader
          from src.config import config
          import tempfile
          import os

          # Test document loader initialization
          dl = DocumentLoader()
          print('Document loader initialized successfully')

          # Test automatic enhanced processing detection
          dolphin_enabled = config.get('dolphin', {}).get('enabled', False)
          has_enhanced_processor = dl.enhanced_processor is not None
          print(f'Dolphin enabled in config: {dolphin_enabled}')
          print(f'Enhanced processor available: {has_enhanced_processor}')

          # Test with a simple text file
          with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
              f.write('This is a test document for enhanced processing.')
              temp_file = f.name

          try:
              chunks = dl.load_single_document(temp_file)
              print(f'Successfully processed document into {len(chunks)} chunks')
              assert len(chunks) > 0, 'Should produce at least one chunk'
              print('Enhanced document processing: PASSED')
          finally:
              os.unlink(temp_file)
          "

      - name: Validate backend reliability features
        run: |
          $env:PYTHONPATH = "$env:GITHUB_WORKSPACE"
          python -c "
          # Comprehensive test of backend reliability features
          from src.service_manager import get_service_manager
          import time

          sm = get_service_manager()

          # Test error recovery with retry
          call_count = [0]
          def failing_operation():
              call_count[0] += 1
              if call_count[0] < 3:
                  raise ValueError('Temporary failure')
              return 'success'

          result = sm.execute_sync('document_processing', failing_operation)
          assert result == 'success'
          assert call_count[0] == 3
          print('Error recovery with retry: PASSED')

          # Test async execution
          future = sm.execute_async('llm_generation', lambda: 'async_result')
          async_result = future.result(timeout=5)
          assert async_result == 'async_result'
          print('Async execution: PASSED')

          # Test health monitoring
          status = sm.get_system_status()
          assert 'threads' in status
          assert 'health' in status
          assert 'errors' in status
          assert status['health']['overall_status'] in ['healthy', 'warning', 'critical']
          print('Health monitoring: PASSED')

          # Test thread pool management
          thread_status = status['threads']
          assert 'active_tasks' in thread_status
          assert 'max_workers' in thread_status
          print('Thread pool management: PASSED')

          sm.shutdown(wait=True)
          print('Backend reliability validation: ALL PASSED')
          "

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml

      - name: Run linting (optional)
        run: |
          pip install flake8
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
          # Lint new backend service files with stricter rules
          flake8 src/thread_manager.py src/error_recovery.py src/health_monitor.py src/service_manager.py --count --max-complexity=8 --max-line-length=100 --statistics

  build:
    runs-on: windows-latest
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt
          python -m pip install -r requirements-dev.txt

      - name: Build executable
        run: |
          pip install pyinstaller
          # Build with enhanced processing support
          pyinstaller --onefile --exclude-module tensorflow --exclude-module tf_keras --exclude-module sklearn src/main.py --name cubo
          # Also build the GUI launcher
          pyinstaller --onefile --exclude-module tensorflow --exclude-module tf_keras --exclude-module sklearn launch_gui.py --name cubo-gui

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: cubo-executables
          path: |
            dist/cubo.exe
            dist/cubo-gui.exe
